**Choose your language / Wybierz jÄ™zyk**

[EN](#english) / [PL](#polski)

#### English

# Multidimensional Olympic Data Analysis

## Table of Contents

1. [Description](#description)
2. [Required before use (important)](#required-before-use-(important))
3. [Data and ETL processes](#data-and-etl-processes)
4. [Docker and MS SQL Server](#docker-and-ms-sql-server)
5. [KPI File](#kpi-file)
6. [Dash Application](#dash-application)
7. [Data Mining](#data-mining)
8. [License](#license)
9. [Authors](#authors)

## Description



## Required before use (important)

If you want to run this project on your computer or create your own similar one, you must meet several requirements:

1. Make sure you have HADOOP installed on your computer. If not you can install it by following this tutorial:
   ```sh
   https://www.youtube.com/watch?v=knAS0w-jiUk
   ```

2. Make sure you have Apache Spark installed on your computer. If not you can install it by following this tutorial:
   ```sh
   https://www.youtube.com/watch?v=OmcSTQVkrvo
   ```
3. Make sure you have Docker Desktop installed on your computer. If not, you can install it by downloading the installer from the official Docker website:
   ```sh
   https://www.docker.com/products/docker-desktop/
   ```

4. Make sure you have docker compose module installed on your computer. If not, you can install it by following this tutorial:
   ```sh
   [WINDOWS] - https://www.ionos.com/digitalguide/server/configuration/install-docker-compose-on-windows/

   [LINUX] - https://gcore.com/learning/how-to-install-docker-compose-on-linux/
   ```
   
5. Make sure you have installed the required Python libraries used in the project. If not you can install them by downloading the `requirements.txt` file and running the following command:
   ```sh
   pip install -r requirements.txt
   ```
6. Clone the repository to your local computer:
   ```sh
   git clone https://github.com/PiotrGren/Multidimensional-Olympic-Data-Analysis
   cd Multidimensional-Olympic-Data-Analysis
   ```

## Data and ETL processes

The repository uses Olympic data, which can be found in a CSV file in the Dane/ directory. The main data files are:

 - athlete_events.csv: Contains information about athletes, Olympic events, achievements, etc. spanning the years 1890-2016.
 - country-codes.csv: Contains information about abbreviations of countries and the continents they are from (needed to create a new column with continents in the data frame used).

### ETL

ETL processes carried out on the original data frame loaded using the pandas library are carried out in the `ETL.ipynb` file. The file contains processes such as data transformation (e.g., converting M, F values in the Sex column to Male, Female, or converting ages to age ranges), generating new columns (e.g., by splitting the Games column, or adding a new column with continents, or converting the data type (e.g., from str to integer).

## Docker and MS SQL Server

### docker-compose.yml

The docker-compose.yml file in the repository is used to define and run multi-container applications using Docker. In this case, this file configures a container with Microsoft SQL Server.

**How to Run**

1 Make sure you have installed Docker Desktop and docker-compose correctly.
2.Make sure you have cloned the repository to your computer or created your own with your own docker-compose file and downloaded the `mssql-jdbc-12.6.1.jre8` driver (or your corresponding version).
3 Go to the folder with the docker-compose file.
   ```sh
   cd path/to/your/folder
   ```
4. Make sure you have Docker Engine running (run Docker Desktop on your computer).
5. Run docker-compose by running the command:
   ```sh
   docker-compose up
   ```
6. If you have run the process correctly, from now on, a new container should appear in Docker Desktop. From now on, you can start and stop it in the application.

### MS SQL Server

Microsoft SQL Server is a relational database management system (RDBMS) developed by Microsoft. It is used to store and manage data and supports a wide range of operations, including SQL queries, data analysis, report generation and integration with other applications.

In this project, MS SQL Server will be used to store processed Olympic data, which will then be used for analysis and visualization.

#### Benefits of running MS SQL Server in a container

1 **Isolation**: Containers isolate applications and their dependencies, allowing multiple versions of SQL Server to run side-by-side without conflicts.
2 **Portability**: Containers can be easily moved between different environments (e.g., development, test and production).
3. **Speed of deployment**: Containers allow rapid deployment and scaling of applications.
4. **Consistency**: Using containers ensures that the application runs the same in all environments, eliminating system configuration issues.

### Python files to start with

1. **CREATE_DATABASE.py** - This script is used to create a database in MS SQL Server. It executes SQL statements that create a new database and then creates the tables needed to store the Olympic data.

2. **LOAD_DATA.py** - This script loads the processed data into the MS SQL Server database. It uses the pandas library to load the data from the CSV files and then writes it to the appropriate tables in the database.

3. **CHECK_DATABASE.py** - This script checks whether the database exists, and whether it contains the required tables. This is useful for verifying the state of the database before starting data operations.

4. **DROP_DATABASE_OPTIONAL.py** = This is an optional script that removes the database if it exists. This is useful for cleaning up the environment before restarting ETL processes or testing or deleting the database if you make a mistake or break something.

## KPI File

The KPI.ipynb file is a Jupyter notebook that is used to perform major analysis of Olympic data in the project. In this file, various multivariate analyses are performed to understand the key indicators related to the participation and performance of athletes in the Olympic Games. The analysis is carried out divided into 4 scenarios, respectively:

1. **Scenario 1**: Athletes' achievements gained - continental analysis.
2. **Scenario 2**: Medals won - analysis of age patterns in the most popular seasonal sports of the 21st century.
3. **Scenario 3**: Analysis of the anthropometric profile of Polish athletes in the context of their achievements at the Olympic Games after World War II.
4. **Scenario 4**: Analysis of patterns among double gold medalists from Europe who won double gold in one sport.

### Purpose and content

The KPI.ipynb file is used to perform preliminary data analysis and test various scenarios that are later implemented in the Dash application. It is a test file that allows you to experiment with data and create and visualize various metrics and anaiz before their final implementation.

Each scenario is analyzed in detail, and the results are visualized using charts and tables. As a result of these analyses, preliminary versions of charts and reports are created, which serve as the basis for further development and implementation in the Dash application.

### Remember

Keep in mind that KPI.ipynb is a test file that is used to experiment and test different approaches to data analysis. The final versions of all analytical processes and charts created and run in this file are included in the Dash application. The Dash app integrates these analyses into an interactive and user-friendly environment, allowing dynamic viewing and analysis of Olympic data.

The KPI.ipynb file plays a key role in the project lifecycle, enabling rapid prototyping and testing of ideas, which are then transferred to the final Dash application.

## Dash application

The Dash application in this project is an interactive platform for visualizing and analyzing Olympic data. Dash, developed by Plotly, is a framework for building analytical web applications using Python. It allows the creation of interactive charts and dashboards that can be easily integrated with various data sources.

### Application Structure

The structure of the Dash application in this project consists of the following:

1. application main file (`app.py`):
    - The main file responsible for running the application.
    - Dash application configuration, including layout and styling.

2. layout:
    - Defines the layout of the application, including the arrangement of components on the page.
    - It consists of containers, rows and columns that organize the various UI elements.

3. Styles:
    - Application styling is implemented using CSS, which can be included directly in Python code or in a separate CSS file (if in a separate file, place it in the assets folder).
    - External CSS libraries are used, such as Dash Bootstrap Components, which provide ready-made UI components.

4 Components:
    - Dash components are UI elements such as charts, tables, forms, buttons and more.
    - Each component is created using the Dash library and can be interactive.

5 Callbacks:
    - Callbacks are functions that define the interactivity of an application.
    - They respond to user actions such as clicks, typing text, changing values on sliders, etc.
    - Callbacks update components in real time based on user inputs.

### Files in the Project

1. `app.py`:
    - This file contains the main configuration of the Dash application.
    - It defines the application layout and initializes the components.

2. assets/:
    - A directory containing CSS files and other static resources.
    - CSS files in this directory are automatically loaded by Dash.

3. data/:
    - A directory containing data used by the application.
    - Data can be loaded from CSV files, databases or other sources.

4. pages/:
    - A directory containing the sub-pages of the Dash application.
    - Sub-pages contained in this directory are automatically visible to the application
    1. `pages/scc1.py` - a file that performs analysis according to [first scenario](#scenario-1) and generates charts from the performed analysis, everything is combined into an interactive dashboard of the performed and visualized analysis
    2. `pages/scc2.py` - a file that performs the analysis according to [the second scenario](#scenario-2) and generates graphs from the analysis performed, the results are also presented on an interactive dashboard
    3. `pages/scc3.py` - another file that performs the analysis according to [the third scenario](#scenario-3) and generates an interactive dashboard with graphs from the analyses performed
    4. `pages/scc4.py` - the last file performing analyses and generating an interactive dashboard based on them, the file performs a multivariate analysis according to [the last scenario](#scenario-4)
    5. `pages/home.py` - a file that generates a home subpage, which contains a very brief description of the issue being pursued
  
### How to Edit an Application

1 Editing the Layout:
    - You can edit the layout of the application by modifying the layout section in the `app.py` file or by changing the layout of each subpage separately in its file in the pages/ directory.
    - Adding new components, changing existing ones, organizing them into containers, rows and columns.

2 Adding New Components:
    - New components can be added in the layout section.
    - You need to define component properties such as id, styles and their contents.

3. Modifying Styles:
    - Styles can be edited by modifying CSS files in the assets/ directory, or by adding styles to components while still in the source code in Python.
    - New styles can be added or existing styles can be modified to customize the look of the application.

4 Adding New Functionality:
    - New functionalities can be added by defining new callbacks in the sceanriusze files in the pages/ directory.
    - Callbacks connect the user interface to the application logic, enabling interactivity and dynamic updates.

5 Adding new application pages
    - New pages can be added by creating a new page in Python (e.g., along the lines of existing ones) and saving it in the pages/ directory.
    - To make the Dash application automatically see the page, place it in pages/ catalog and add the following line in the code:
      ```sh
      dash.register_page(__name__, title='[your_page_title]')
      ```

## Data Mining

Data Mining is the process of discovering patterns, correlations, and anomalies within large datasets to predict outcomes. Using a variety of techniques such as machine learning, statistics, and database systems, Data Mining transforms raw data into useful information. It is a crucial aspect of data analysis, enabling data-driven decision-making by identifying trends and relationships that may not be immediately evident.

### Purpose of Data Mining in This Application

In the context of this Olympic data analysis application, Data Mining is employed to uncover valuable insights from the historical performance data of athletes, countries, and events. The main objectives include:

1. Identifying trends and patterns in the performance of countries and athletes over time.

2. Predicting future outcomes based on historical data.

3. Highlighting significant factors contributing to athletic success.

4. Visualizing complex datasets to facilitate easy interpretation and analysis.

### Implementation of data mining in the application.

Data mining processes are implemented in 4 scripts in the repository, each script performs Data Mining for a separate scenario.

These files are respectively: `S1_DM.py`, `S2_DM.py`, `S3_DM.py`, `S4_DM.py`.

Each file performs the Data Mining process using machine learning models such as ARIMA, Random Forest, etc. The results of the process are presented in graphs, and these are exported to files with .png extension.
Ultimately, we can view the results in the Dash application because they are added there.

**Exception**: The only exception is the DataMining process in Scenario 3, in which it is carried out in the app, and then an interactive 3D graph is generated showing the relationships between certain anthropometric characteristics of the athletes and their chances of winning a medal.

By leveraging Data Mining techniques, this application provides a robust platform for analyzing Olympic data, offering valuable insights and predictions that can be used by researchers, analysts, and sports enthusiasts.

## License

This project is licensed under the MIT License. See the LICENSE.txt file for details.

## Authors

Piotr GreÅ„ = Co-developer - https://github.com/PiotrGren

Gabriela Kiwacka - Co-developer - https://github.com/GabrielaKiwacka



#### Polski

# Wielowymiarowa Analiza Danych Olimpijskich

## Spis treÅ›ci

1. [Opis](#opis)
2. [Wymagane przed uÅ¼yciem (waÅ¼ne)](#wymagane-przed-uÅ¼yciem-(waÅ¼ne))
3. [Dane i procesy ETL](#dane-i-procesy-etl)
4. [Docker i MS SQL Server](#docker-i-ms-sql-server)
5. [Plik KPI](#plik-kpi)
6. [Aplikacja Dash](#aplikacja-dash)
7. [Data Mining](#data-mining)
8. [Licencja](#licencja)
9. [Autorzy](#autorzy)

## Opis



## Wymagane przed uÅ¼yciem (waÅ¼ne)

JeÅ¼eli chcesz uruchomiÄ‡ ten projekt u siebie na komputerze lub stworzyÄ‡ wÅ‚asny podobny musisz speÅ‚niÄ‡ kilka wymogÃ³w:

1. Upewnij siÄ™, Å¼e masz zainstalowany HADOOP na swoim komputerze. JeÅ¼eli nie, to moÅ¼esz go zainstalowaÄ‡ wykonujÄ…c ten tutorial:
   ```sh
   https://www.youtube.com/watch?v=knAS0w-jiUk
   ```

2. Upewnij siÄ™, Å¼e masz zainstalowany Apache Spark na swoim komputerze. JeÅ¼eli nie, to moÅ¼esz go zainstalowaÄ‡ wykonujÄ…c ten tutorial:
   ```sh
   https://www.youtube.com/watch?v=OmcSTQVkrvo
   ```

3. Upewnij siÄ™, Å¼e masz zainstalowany Docker Desktop na swoim komputerze. JeÅ¼eli nie, to moÅ¼esz go zainstalowaÄ‡ pobierajÄ…c instalator z oficjalnej strony Docker:
   ```sh
   https://www.docker.com/products/docker-desktop/
   ```

4. Upewnij siÄ™, Å¼e masz zainstalowany moduÅ‚ docker compose na swoim komputerze. JeÅ¼eli nie, to moÅ¼esz go zainstalowaÄ‡ wykonujÄ…c wybrany tutorial:
   ```sh
   [WINDOWS] - https://www.ionos.com/digitalguide/server/configuration/install-docker-compose-on-windows/

   [LINUX] - https://gcore.com/learning/how-to-install-docker-compose-on-linux/
   ```

5. Upewnij siÄ™, Å¼e masz zainstalowane wymagane biblioteki Python, uÅ¼yte w projekcie. JeÅ¼eli nie moÅ¼esz je zainstalowaÄ‡ pobierajÄ…c plik `requirements.txt` i wykonujÄ…c poniÅ¼sze polecenie:
   ```sh
   pip install -r requirements.txt
   ```

6. Sklonuj repozytorium na swÃ³j lokalny komputer:
   ```sh
   git clone https://github.com/PiotrGren/Multidimensional-Olympic-Data-Analysis
   cd Multidimensional-Olympic-Data-Analysis
   ```

## Dane i procesy ETL

Repozytorium wykorzystuje dane olimpijskie, ktÃ³re moÅ¼na znaleÅºÄ‡ w pliku CSV w katalogu Dane/. GÅ‚Ã³wne pliki z danymi to:

 - athlete_events.csv: Zawiera informacje o sportowcach, wydarzeniach olimpijskich, osiÄ…gniÄ™ciach itd. w zakrasie lat 1890-2016.
 - country-codes.csv: Zawiera informacje o skrÃ³tach paÅ„stw oraz kontynentach, z ktÃ³rych pochodzÄ… (potrzebne do utworzenia nowej kolumny z kontynentami w wykorzystanej ramce danych).

### ETL

Procesy ETL przeprowadzone na oryginalnej ramce danych, wczytanej przy pomocy biblioteki pandas sÄ… przeprowadzone w pliku `ETL.ipynb`. Plik zawiera takie procesy jak transformacja danych (np. zamiana wartoÅ›ci M, F w kolumnie Sex na Male, Female lub zamianÄ™ wieku na przedziaÅ‚y wiekowe), generowanie nowych kolumn (np. poprzez rozdzielenie kolumny Games, lub dodanie nowej kolumny z kontynentami czy teÅ¼ konwersja typu danych (np. z str na integer).

## Docker i MS SQL Server

### docker-compose.yml

Plik docker-compose.yml w repozytorium sÅ‚uÅ¼y do definiowania i uruchamiania aplikacji wielokontenerowych przy uÅ¼yciu Docker. W tym przypadku, plik ten konfiguruje kontener z Microsoft SQL Server.

**Jak uruchomiÄ‡**

1. Upewnij siÄ™, Å¼e zainstalowaÅ‚eÅ› poprawnie Docker Desktop oraz docker-compose.
2. Upewnij siÄ™, Å¼e sklonowaÅ‚eÅ› repozytorium na swÃ³j komputer lub utworzyÅ‚eÅ› wÅ‚asne z wÅ‚asnym plikiem docker-compose i pobraÅ‚eÅ› sterownik `mssql-jdbc-12.6.1.jre8` (lub swojÄ… odpowiadajÄ…cÄ… wymaganiom wersjÄ™).
3. PrzejdÅº do folderu z plikiem docker-compose.
   ```sh
   cd sciezka/do/twojego/folderu
   ```
4. Upewnij siÄ™, Å¼e masz uruchomiony Docker Engine (wÅ‚Ä…cz Docker Desktop na komputerze).
5. Uruchom docker-compose wykonujÄ…c polecenie:
   ```sh
   docker-compose up
   ```
6. JeÅ¼eli poprawnie przeprowadziÅ‚eÅ› proces, od teraz w aplikacji Docker Desktop powinien pojawiÄ‡ siÄ™ nowy kontener. Od teraz moÅ¼esz uruchamiaÄ‡ i zatrzymywaÄ‡ go w aplikacji.

### MS SQL Server

Microsoft SQL Server to system zarzÄ…dzania relacyjnymi bazami danych (RDBMS) opracowany przez firmÄ™ Microsoft. Jest uÅ¼ywany do przechowywania i zarzÄ…dzania danymi oraz wspiera szeroki zakres operacji, w tym zapytania SQL, analizy danych, tworzenie raportÃ³w i integracjÄ™ z innymi aplikacjami.

W tym projekcie, MS SQL Server bÄ™dzie uÅ¼ywany do przechowywania przetworzonych danych olimpijskich, ktÃ³re nastÄ™pnie bÄ™dÄ… wykorzystywane do analiz i wizualizacji.

#### KorzyÅ›ci ze stawiania MS SQL Server w kontenerze

1. **Izolacja**: Kontenery izolujÄ… aplikacje i ich zaleÅ¼noÅ›ci, co pozwala na uruchamianie wielu wersji serwera SQL obok siebie bez konfliktÃ³w.
2. **PrzenoÅ›noÅ›Ä‡**: Kontenery mogÄ… byÄ‡ Å‚atwo przenoszone miÄ™dzy rÃ³Å¼nymi Å›rodowiskami (np. deweloperskim, testowym i produkcyjnym).
3. **SzybkoÅ›Ä‡ wdroÅ¼enia**: Kontenery pozwalajÄ… na szybkie wdraÅ¼anie i skalowanie aplikacji.
4. **SpÃ³jnoÅ›Ä‡**: UÅ¼ycie kontenerÃ³w zapewnia, Å¼e aplikacja dziaÅ‚a tak samo we wszystkich Å›rodowiskach, co eliminuje problemy zwiÄ…zane z konfiguracjÄ… systemu.

### Pliki Pythona, od ktÃ³rych naleÅ¼y zaczÄ…Ä‡

1. **CREATE_DATABASE.py** - Ten skrypt sÅ‚uÅ¼y do tworzenia bazy danych w MS SQL Server. Wykonuje on polecenia SQL, ktÃ³re tworzÄ… nowÄ… bazÄ™ danych, a nastÄ™pnie tworzy tabele potrzebne do przechowywania danych olimpijskich.

2. **LOAD_DATA.py** - Ten skrypt Å‚aduje przetworzone dane do bazy danych MS SQL Server. Korzysta z biblioteki pandas do wczytania danych z plikÃ³w CSV, a nastÄ™pnie zapisuje je do odpowiednich tabel w bazie danych.

3. **CHECK_DATABASE.py** - Ten skrypt sprawdza, czy baza danych istnieje, oraz czy zawiera wymagane tabele. Jest to przydatne do weryfikacji stanu bazy danych przed rozpoczÄ™ciem operacji na danych.

4. **DROP_DATABASE_OPTIONAL.py** = Jest to opcjonalny skrypt, ktÃ³ry usuwa bazÄ™ danych, jeÅ›li istnieje. Jest to przydatne do czyszczenia Å›rodowiska przed ponownym uruchomieniem procesÃ³w ETL lub testowaniem lub usuniÄ™ciem bazy jeÅ¼eli popeÅ‚nimy bÅ‚Ä…d lub coÅ› zepsujemy.

## Plik KPI

Plik KPI.ipynb jest notebookiem Jupyter, ktÃ³ry sÅ‚uÅ¼y do przeprowadzania gÅ‚Ã³wnych analiz danych olimpijskich w projekcie. W tym pliku wykonywane sÄ… rÃ³Å¼ne analizy wielowymiarowe majÄ…ce na celu zrozumienie kluczowych wskaÅºnikÃ³w zwiÄ…zanych z uczestnictwem i osiÄ…gniÄ™ciami sportowcÃ³w w Igrzyskach Olimpijskich. Analiza przeprowadzana jest z podziaÅ‚em na 4 scenariusze, odpowiednio:

1. **Scenariusz 1**: Zdobyte osiÄ…gniÄ™cia sportowcÃ³w - analiza kontynentalna.
2. **Scenariusz 2**: Zdobyte medale - analiza wzorcÃ³w wiekowych w najpopularniejszych dyscyplinach sezonowych XXI w.
3. **Scenariusz 3**: Analiza profilu antropometrycznego polskich sportowcÃ³w w kontekÅ›cie zdobytych osiÄ…gniÄ™Ä‡ na igrzyskach olimpijskich po II WÅš.
4. **Scenariusz 4**: Analiza wzorcÃ³w wÅ›rÃ³d podwÃ³jnych zÅ‚otych medalistÃ³w z Europy, ktÃ³rzy zdobyli podwÃ³jne zÅ‚oto w jednej dziedzinie sportowej.

### Cel i zawartoÅ›Ä‡

Plik KPI.ipynb jest wykorzystywany do przeprowadzenia wstÄ™pnych analiz danych oraz testowania rÃ³Å¼nych scenariuszy, ktÃ³re pÃ³Åºniej sÄ… implementowane w aplikacji Dash. Jest to plik testowy, ktÃ³ry pozwala na eksperymentowanie z danymi oraz tworzenie i wizualizacjÄ™ rÃ³Å¼nych wskaÅºnikÃ³w oraz anaiz przed ich ostatecznÄ… implementacjÄ….

KaÅ¼dy z tych scenariuszy jest szczegÃ³Å‚owo analizowany, a wyniki sÄ… wizualizowane przy uÅ¼yciu wykresÃ³w i tabel. W wyniku tych analiz powstajÄ… wstÄ™pne wersje wykresÃ³w i raportÃ³w, ktÃ³re sÅ‚uÅ¼Ä… jako podstawa do dalszego rozwoju i implementacji w aplikacji Dash.

### PamiÄ™taj

NleÅ¼y pamiÄ™taÄ‡, Å¼e KPI.ipynb jest plikiem testowym, ktÃ³ry sÅ‚uÅ¼y do eksperymentowania i testowania rÃ³Å¼nych podejÅ›Ä‡ do analizy danych. Ostateczne wersje wszystkich procesÃ³w analitycznych oraz wykresÃ³w tworzonych i przeprowadzanych w tym pliku sÄ… zawarte w aplikacji Dash. Aplikacja Dash integruje te analizy w interaktywne i przyjazne dla uÅ¼ytkownika Å›rodowisko, umoÅ¼liwiajÄ…c dynamiczne przeglÄ…danie i analizowanie danych olimpijskich.

Plik KPI.ipynb odgrywa kluczowÄ… rolÄ™ w cyklu Å¼ycia projektu, umoÅ¼liwiajÄ…c szybkie prototypowanie i testowanie pomysÅ‚Ã³w, ktÃ³re sÄ… nastÄ™pnie przenoszone do ostatecznej aplikacji Dash.

## Aplikacja Dash

Aplikacja Dash w tym projekcie jest interaktywnÄ… platformÄ… do wizualizacji i analizy danych olimpijskich. Dash, opracowany przez Plotly, jest frameworkiem do budowy analitycznych aplikacji webowych przy uÅ¼yciu Pythona. UmoÅ¼liwia tworzenie interaktywnych wykresÃ³w i dashboardÃ³w, ktÃ³re moÅ¼na Å‚atwo integrowaÄ‡ z rÃ³Å¼nymi ÅºrÃ³dÅ‚ami danych.

### Struktura Aplikacji

Struktura aplikacji Dash w tym projekcie skÅ‚ada siÄ™ z nastÄ™pujÄ…cych elementÃ³w:

1. Plik gÅ‚Ã³wny aplikacji (`app.py`):
    - GÅ‚Ã³wny plik odpowiedzialny za uruchomienie aplikacji.
    - Konfiguracja aplikacji Dash, w tym layout i stylizacja.

2. Layout:
    - Definiuje ukÅ‚ad aplikacji, w tym rozmieszczenie komponentÃ³w na stronie.
    - SkÅ‚ada siÄ™ z kontenerÃ³w, rzÄ™dÃ³w i kolumn, ktÃ³re organizujÄ… rÃ³Å¼ne elementy interfejsu uÅ¼ytkownika.

3. Style:
    - Stylizacja aplikacji jest realizowana przy uÅ¼yciu CSS, ktÃ³re moÅ¼e byÄ‡ zaÅ‚Ä…czone bezpoÅ›rednio w kodzie Pythona lub w osobnym pliku CSS (jeÅ¼eli w osobnym pliku naleÅ¼y umieÅ›ciÄ‡ go w folderze assets).
    - UÅ¼ywane sÄ… zewnÄ™trzne biblioteki CSS, takie jak Dash Bootstrap Components, ktÃ³re dostarczajÄ… gotowe komponenty UI.

4. Komponenty:
    - Komponenty Dash to elementy interfejsu uÅ¼ytkownika, takie jak wykresy, tabele, formularze, przyciski i inne.
    - KaÅ¼dy komponent jest tworzony przy uÅ¼yciu biblioteki Dash i moÅ¼e byÄ‡ interaktywny.

5. Callbacki:
    - Callbacki to funkcje, ktÃ³re definiujÄ… interaktywnoÅ›Ä‡ aplikacji.
    - OdpowiadajÄ… na dziaÅ‚ania uÅ¼ytkownika, takie jak klikniÄ™cia, wpisywanie tekstu, zmiana wartoÅ›ci na suwakach, itp.
    - Callbacki aktualizujÄ… komponenty w czasie rzeczywistym na podstawie wejÅ›Ä‡ uÅ¼ytkownika.
  
### Pliki w Projekcie

1. `app.py`:
    - Plik ten zawiera gÅ‚Ã³wnÄ… konfiguracjÄ™ aplikacji Dash.
    - Definiuje ukÅ‚ad aplikacji i inicjalizuje komponenty.

2. assets/:
    - Katalog zawierajÄ…cy pliki CSS i inne zasoby statyczne.
    - Pliki CSS w tym katalogu sÄ… automatycznie Å‚adowane przez Dash.

3. Dane/:
    - Katalog zawierajÄ…cy dane wykorzystywane przez aplikacjÄ™.
    - Dane mogÄ… byÄ‡ Å‚adowane z plikÃ³w CSV, baz danych lub innych ÅºrÃ³deÅ‚.

4. pages/:
    - Katalog zawierajÄ…cy podstrony aplikacji Dash
    - Podstrony zawarte w tym katalogu sÄ… automatycznie widoczne dla aplikacji
    1. `pages/scc1.py` - plik przeprowadzajÄ…cy analizÄ™ wedÅ‚ug [pierwszego scenariusza](#Scenariusz-1) oraz generujÄ…cy wykresy z przeprowadzonych analiz, wszystko poÅ‚Ä…czone jest w interaktywny dashboard z przeprowadzonej i zwizualizowanej analizy
    2. `pages/scc2.py` - plik przeprowadzajÄ…cy analizÄ™ wedÅ‚ug [drugiego scenariusza](#Scenariusz-2) oraz generujÄ…cy wykresy z przeprowadzonych analiz, wyniki rÃ³wnieÅ¼ przedstawione sÄ… na interaktywnym dashboardzie
    3. `pages/scc3.py` - kolejny plik przeprowadzajÄ…cy analizÄ™ wedÅ‚ug [trzeciego scenariusza](#Scenariusz-3) oraz generujÄ…cy  interaktywny dashboard z wykresami z przeprowadzonych analiz
    4. `pages/scc4.py` - ostatni plik przeprowadzajÄ…cy analizy i generujÄ…cy na ich podstawie interaktywny dashboard, plik realizuje wielowmiarowÄ… nalizÄ™ wedÅ‚ug [ostatniego scenariusza](#Scenariusz-4)
    5. `pages/home.py` - plik generujÄ…cy podstronÄ™ domowÄ…, na ktÃ³rej zawarty jest bardzo krÃ³tki opis realizowanego zagadnienia
  
### Jak EdytowaÄ‡ AplikacjÄ™

1. Edytowanie Layoutu:
    - Layout aplikacji moÅ¼na edytowaÄ‡, modyfikujÄ…c sekcjÄ™ layout w pliku `app.py` lub poprzez zmianÄ™ layoutu kaÅ¼dej podstrony z osobna w jej pliku w katalogu pages/.
    - Dodawanie nowych komponentÃ³w, zmiana istniejÄ…cych, organizowanie ich w kontenery, rzÄ™dy i kolumny.

2. Dodawanie Nowych KomponentÃ³w:
    - Nowe komponenty moÅ¼na dodaÄ‡ w sekcji layout.
    - NaleÅ¼y zdefiniowaÄ‡ wÅ‚aÅ›ciwoÅ›ci komponentÃ³w, takie jak id, style oraz ich zawartoÅ›Ä‡.

3. Modyfikacja StylÃ³w:
    - Style moÅ¼na edytowaÄ‡, modyfikujÄ…c pliki CSS w katalogu assets/, lub poprzez dodanie styli do komponentÃ³w jeszcze w kodzie ÅºrÃ³dÅ‚owym w Pythonie.
    - MoÅ¼na dodaÄ‡ nowe style lub zmieniÄ‡ istniejÄ…ce, aby dostosowaÄ‡ wyglÄ…d aplikacji.

4. Dodawanie Nowych FunkcjonalnoÅ›ci:
    - Nowe funkcjonalnoÅ›ci moÅ¼na dodaÄ‡, definiujÄ…c nowe callbacki w plikach sceanriuszy w katalogu pages/.
    - Callbacki Å‚Ä…czÄ… interfejs uÅ¼ytkownika z logikÄ… aplikacji, umoÅ¼liwiajÄ…c interaktywnoÅ›Ä‡ i dynamiczne aktualizacje.

5. Dodawanie nowych stron aplikacji
    - Nowe strony moÅ¼na dodaÄ‡ poprzez stworzenie nowej strony w Pythonie (np na wzÃ³r juÅ¼ istniejÄ…cych) i zapisanie jej w katalogu pages/
    - Aby aplikacja Dash automatycznie widziaÅ‚a stronÄ™ naleÅ¼y umieÅ›ciÄ‡ jÄ… w katalogu pages/ oraz dodaÄ‡ w kodzie poniÅ¼szÄ… linijkÄ™:
      ```sh
      dash.register_page(__name__, title='[twÃ³j_tytuÅ‚_strony]')
      ```

## Data Mining

Data Mining to proces odkrywania wzorcÃ³w, korelacji i anomalii w duÅ¼ych zbiorach danych w celu przewidywania wynikÃ³w. KorzystajÄ…c z rÃ³Å¼nych technik, takich jak uczenie maszynowe, statystyka i systemy baz danych, Data Mining przeksztaÅ‚ca surowe dane w przydatne informacje. Jest to kluczowy aspekt analizy danych, umoÅ¼liwiajÄ…cy podejmowanie decyzji w oparciu o dane poprzez identyfikacjÄ™ trendÃ³w i relacji, ktÃ³re mogÄ… nie byÄ‡ od razu widoczne.

### Cel Data Mining w tej aplikacji

W kontekÅ›cie tej aplikacji do analizy danych olimpijskich, eksploracja danych (Data Mining) jest wykorzystywana do odkrywania cennych spostrzeÅ¼eÅ„ z historycznych danych dotyczÄ…cych wynikÃ³w sportowcÃ³w, krajÃ³w i wydarzeÅ„. GÅ‚Ã³wne cele obejmujÄ…:

1. Identyfikacja trendÃ³w i wzorcÃ³w w wynikach krajÃ³w i sportowcÃ³w w czasie.

2. Przewidywanie przyszÅ‚ych wynikÃ³w na podstawie danych historycznych.

3. PodkreÅ›lanie istotnych czynnikÃ³w przyczyniajÄ…cych siÄ™ do sukcesu sportowego.

4. Wizualizacja zÅ‚oÅ¼onych zestawÃ³w danych w celu uÅ‚atwienia interpretacji i analizy.

### Implementacja eksploracji danych w aplikacji

Procesy eksploracji danych sÄ… zaimplementowane w 4 skryptach w repozytoirum, kaÅ¼dy skrypt przeprowadza Data Mining dla osobnego scenariusza.

Te pliki to odpowiednio: `S1_DM.py`, `S2_DM.py`, `S3_DM.py`, `S4_DM.py`

KaÅ¼dy plik przeprowadza proces Data Mining z wykorzystaniem modeli nauczania maszynowego takich jak np. ARIMA, Random Forest itp. Wyniki procesu przedstawiane sÄ… na wykresach, a te eksportowane sÄ… do plikÃ³w z rozszerzeniem .png.
Ostatecznie wyniki moÅ¼emy przeglÄ…daÄ‡ w aplikacji Dash poniewaÅ¼ sÄ… one tam dodane.

**WyjÄ…tek**: Jedynym wyjÄ…tkiem jest proces DataMining w scenariuszu 3, w ktÃ³rym to jest on przeprowadzany w aplikacji, a nastÄ™pnie generowany jest interaktywny wykres 3D przedstawiajÄ…cy zaleÅ¼noÅ›ci pomiÄ™dzy niektÃ³rymi cechami antropometrycznymi sportowcÃ³w, a ich szansÄ… na zdobycie medalu.

WykorzystujÄ…c techniki Data Mining, aplikacja ta zapewnia solidnÄ… platformÄ™ do analizy danych olimpijskich, oferujÄ…c cenne spostrzeÅ¼enia i prognozy, ktÃ³re mogÄ… byÄ‡ wykorzystywane przez badaczy, analitykÃ³w i entuzjastÃ³w sportu.

## Licencja

Ten projekt jest dostÄ™pny na licencji MIT. SzczegÃ³Å‚y moÅ¼na znaleÅºÄ‡ w pliku `LICENSE.txt`.

## Autorzy

Piotr GreÅ„ - Co-developer - https://github.com/PiotrGren

Gabriela Kiwacka - Co-developer - https://github.com/GabrielaKiwacka
